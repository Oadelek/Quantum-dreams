{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Matching Graphs (Stabilizer Nodes Only) ---\n",
      "X-Error Graph (Z-Stabs): 4 nodes, 3 edges. Boundary nodes: [0, 1, 2, 3]\n",
      "Z-Error Graph (X-Stabs): 4 nodes, 2 edges. Boundary nodes: [0, 1, 2, 3]\n",
      "\n",
      "--- Introducing Error ---\n",
      "Applying X error on data qubit 4\n",
      "\n",
      "--- Measuring Stabilizers ---\n",
      "\n",
      "--- Simulating ---\n",
      "Simulation Counts: {'01110010': 1}\n",
      "\n",
      "--- Decoding with PyMatching (MWPM) ---\n",
      "Measured Syndrome (Z0..Z3, X0..X3): [0, 1, 0, 0, 1, 1, 1, 0]\n",
      "Syndrome for X-Error Graph (Nodes 0..3=Z-Stabs): [0, 1, 0, 0]\n",
      "Syndrome for Z-Error Graph (Nodes 0..3=X-Stabs): [1, 1, 1, 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No perfect matching could be found. This likely means that the syndrome has odd parity in the support of a connected component without a boundary.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 229\u001b[0m\n\u001b[0;32m    225\u001b[0m matcher_z \u001b[38;5;241m=\u001b[39m pymatching\u001b[38;5;241m.\u001b[39mMatching(graph_z, boundary_nodes\u001b[38;5;241m=\u001b[39mboundary_z)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# --- Decode ---\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# Pass the syndrome array corresponding ONLY to the stabilizer nodes\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m correction_x_indices \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msyndrome_x_part\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_corrected_Jeg_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m correction_z_indices \u001b[38;5;241m=\u001b[39m matcher_z\u001b[38;5;241m.\u001b[39mdecode(syndrome_z_part, return_corrected_Jeg_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# The returned indices refer to edges in the graph's internal representation.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# It's often easier to get the correction in terms of which *nodes* need flipping.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Let's decode again to get the correction array (size = num_nodes = num_stabilizers)\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# correction_array[i] = 1 means node i needs correction relative to the MWPM solution\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymatching\\matching.py:324\u001b[0m, in \u001b[0;36mMatching.decode\u001b[1;34m(self, z, _legacy_num_neighbours, _legacy_return_weight, return_weight, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m     return_weight \u001b[38;5;241m=\u001b[39m _legacy_return_weight\n\u001b[0;32m    323\u001b[0m detection_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_syndrome_array_to_detection_events(z)\n\u001b[1;32m--> 324\u001b[0m correction, weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matching_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetection_events\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_weight:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correction, weight\n",
      "\u001b[1;31mValueError\u001b[0m: No perfect matching could be found. This likely means that the syndrome has odd parity in the support of a connected component without a boundary."
     ]
    }
   ],
   "source": [
    "# Import necessary Qiskit components\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit_aer import AerSimulator # Use AerSimulator for simulation\n",
    "import numpy as np\n",
    "import pymatching # <<< Added\n",
    "import networkx as nx # Optional: For graph visualization if needed\n",
    "import matplotlib.pyplot as plt # Optional: For graph visualization\n",
    "\n",
    "# --- Configuration for d=3 Rotated Surface Code (Same as before) ---\n",
    "TOTAL_QUBITS = 17\n",
    "NUM_SYNDROME_BITS = 8 # 4 Z-stabilizers, 4 X-stabilizers\n",
    "\n",
    "# Data Qubits (9 total)\n",
    "DATA_QUBITS = [1, 3, 4, 5, 7, 9, 11, 12, 13]\n",
    "\n",
    "# Measure Qubits (Ancillas - 8 total)\n",
    "Z_ANCILLAS = [0, 2, 8, 10] # Indices for Z-stabilizer measurements\n",
    "X_ANCILLAS = [6, 14, 15, 16] # Indices for X-stabilizer measurements\n",
    "MEASURE_QUBITS = Z_ANCILLAS + X_ANCILLAS\n",
    "\n",
    "# Stabilizer definitions (Same as before)\n",
    "stabilizers = {\n",
    "    0:  {'type': 'Z', 'data_qubits': [1, 3]}, 2:  {'type': 'Z', 'data_qubits': [1, 4, 5, 7]},\n",
    "    8:  {'type': 'Z', 'data_qubits': [7, 9, 11, 12]}, 10: {'type': 'Z', 'data_qubits': [9, 13]},\n",
    "    6:  {'type': 'X', 'data_qubits': [3, 4, 9, 11]}, 14: {'type': 'X', 'data_qubits': [5, 12]},\n",
    "    15: {'type': 'X', 'data_qubits': [11, 13]}, 16: {'type': 'X', 'data_qubits': [7, 12]},\n",
    "}\n",
    "\n",
    "# Map ancilla index to syndrome bit index (Same as before)\n",
    "syndrome_bit_map = {\n",
    "    0: 0, 2: 1, 8: 2, 10: 3, # Z ancillas -> syndrome bits 0-3\n",
    "    6: 4, 14: 5, 15: 6, 16: 7 # X ancillas -> syndrome bits 4-7\n",
    "}\n",
    "ancilla_order_for_syndrome = Z_ANCILLAS + X_ANCILLAS\n",
    "\n",
    "# --- Helper Function for Stabilizer Measurement (Same as before) ---\n",
    "def measure_stabilizer(qc, measure_qubit, stab_info, cl_bit_index):\n",
    "    stab_type = stab_info['type']\n",
    "    data_qubits = stab_info['data_qubits']\n",
    "    qc.reset(measure_qubit) # Reset ancilla before use\n",
    "    qc.h(measure_qubit)\n",
    "    if stab_type == 'Z':\n",
    "        for dq in data_qubits: qc.cz(measure_qubit, dq)\n",
    "    elif stab_type == 'X':\n",
    "        for dq in data_qubits: qc.cx(measure_qubit, dq)\n",
    "    qc.h(measure_qubit)\n",
    "    qc.measure(measure_qubit, cl_bit_index)\n",
    "\n",
    "# --- REVISED: Function to Build Matching Graphs ---\n",
    "def build_matching_graphs(stabilizers, data_qubits, z_ancillas, x_ancillas):\n",
    "    \"\"\"\n",
    "    Constructs the matching graphs (stabilizer nodes only) and identifies boundary nodes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (graph_x, graph_z, node_map_x, node_map_z, boundary_nodes_x, boundary_nodes_z)\n",
    "            graph_x: nx.Graph for X errors (nodes are Z stabilizers)\n",
    "            graph_z: nx.Graph for Z errors (nodes are X stabilizers)\n",
    "            node_map_x: Maps Z ancilla index to graph_x node index\n",
    "            node_map_z: Maps X ancilla index to graph_z node index\n",
    "            boundary_nodes_x: List of node indices in graph_x connected to boundary\n",
    "            boundary_nodes_z: List of node indices in graph_z connected to boundary\n",
    "    \"\"\"\n",
    "    # --- X-Error Graph (based on Z stabilizers) ---\n",
    "    graph_x = nx.Graph()\n",
    "    node_map_x = {anc: i for i, anc in enumerate(z_ancillas)} # Map Z ancilla index -> node index 0,1,2,3\n",
    "    num_x_nodes = len(z_ancillas)\n",
    "    boundary_nodes_x_set = set() # Store indices of nodes connected to boundary\n",
    "\n",
    "    # Add nodes for Z stabilizers ONLY\n",
    "    for anc_idx, graph_node_idx in node_map_x.items():\n",
    "        graph_x.add_node(graph_node_idx, qubit_ancilla_idx=anc_idx, type='Z-Stabilizer')\n",
    "\n",
    "    # Add edges based on single X errors on data qubits\n",
    "    for dq in data_qubits:\n",
    "        flipped_ancillas = [anc for anc in z_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "\n",
    "        if len(flipped_ancillas) == 1:\n",
    "            # X error on dq connects one Z stabilizer node TO THE BOUNDARY\n",
    "            anc_node_idx = node_map_x[flipped_ancillas[0]]\n",
    "            boundary_nodes_x_set.add(anc_node_idx)\n",
    "            # We might store which qubit causes this boundary connection if needed for interpretation later\n",
    "            # graph_x.nodes[anc_node_idx].setdefault('boundary_error_qubits', []).append(dq)\n",
    "        elif len(flipped_ancillas) == 2:\n",
    "            # X error on dq connects two Z stabilizers\n",
    "            anc_node1 = node_map_x[flipped_ancillas[0]]\n",
    "            anc_node2 = node_map_x[flipped_ancillas[1]]\n",
    "            # Add edge only if it doesn't exist, or update metadata if needed\n",
    "            if not graph_x.has_edge(anc_node1, anc_node2):\n",
    "                 graph_x.add_edge(anc_node1, anc_node2, weight=1, error_data_qubit=[dq], error_type='X')\n",
    "            else:\n",
    "                 # If edge exists, perhaps append the data qubit causing it (if interpretation needs it)\n",
    "                 graph_x[anc_node1][anc_node2].setdefault('error_data_qubit', []).append(dq)\n",
    "\n",
    "\n",
    "    # --- Z-Error Graph (based on X stabilizers) ---\n",
    "    graph_z = nx.Graph()\n",
    "    node_map_z = {anc: i for i, anc in enumerate(x_ancillas)} # Map X ancilla index -> node index 0,1,2,3\n",
    "    num_z_nodes = len(x_ancillas)\n",
    "    boundary_nodes_z_set = set()\n",
    "\n",
    "    # Add nodes for X stabilizers ONLY\n",
    "    for anc_idx, graph_node_idx in node_map_z.items():\n",
    "        graph_z.add_node(graph_node_idx, qubit_ancilla_idx=anc_idx, type='X-Stabilizer')\n",
    "\n",
    "    # Add edges based on single Z errors on data qubits\n",
    "    for dq in data_qubits:\n",
    "        flipped_ancillas = [anc for anc in x_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "\n",
    "        if len(flipped_ancillas) == 1:\n",
    "            anc_node_idx = node_map_z[flipped_ancillas[0]]\n",
    "            boundary_nodes_z_set.add(anc_node_idx)\n",
    "            # graph_z.nodes[anc_node_idx].setdefault('boundary_error_qubits', []).append(dq)\n",
    "        elif len(flipped_ancillas) == 2:\n",
    "            anc_node1 = node_map_z[flipped_ancillas[0]]\n",
    "            anc_node2 = node_map_z[flipped_ancillas[1]]\n",
    "            if not graph_z.has_edge(anc_node1, anc_node2):\n",
    "                graph_z.add_edge(anc_node1, anc_node2, weight=1, error_data_qubit=[dq], error_type='Z')\n",
    "            else:\n",
    "                graph_z[anc_node1][anc_node2].setdefault('error_data_qubit', []).append(dq)\n",
    "\n",
    "\n",
    "    return graph_x, graph_z, node_map_x, node_map_z, list(boundary_nodes_x_set), list(boundary_nodes_z_set)\n",
    "\n",
    "# --- Build the graphs ONCE ---\n",
    "print(\"--- Building Matching Graphs (Stabilizer Nodes Only) ---\")\n",
    "graph_x, graph_z, node_map_x, node_map_z, boundary_x, boundary_z = build_matching_graphs(\n",
    "    stabilizers, DATA_QUBITS, Z_ANCILLAS, X_ANCILLAS\n",
    ")\n",
    "print(f\"X-Error Graph (Z-Stabs): {graph_x.number_of_nodes()} nodes, {graph_x.number_of_edges()} edges. Boundary nodes: {boundary_x}\")\n",
    "print(f\"Z-Error Graph (X-Stabs): {graph_z.number_of_nodes()} nodes, {graph_z.number_of_edges()} edges. Boundary nodes: {boundary_z}\")\n",
    "\n",
    "# Optional: Visualize the graphs\n",
    "# try:\n",
    "#     plt.figure(1)\n",
    "#     pos = nx.spring_layout(graph_x) # Or choose a better layout\n",
    "#     nx.draw(graph_x, pos, with_labels=True, font_weight='bold')\n",
    "#     nx.draw_networkx_nodes(graph_x, pos, nodelist=boundary_x, node_color='red') # Highlight boundary nodes\n",
    "#     plt.title(\"X-Error Matching Graph (Nodes are Z-Stabilizers)\")\n",
    "#     plt.figure(2)\n",
    "#     pos = nx.spring_layout(graph_z)\n",
    "#     nx.draw(graph_z, pos, with_labels=True, font_weight='bold')\n",
    "#     nx.draw_networkx_nodes(graph_z, pos, nodelist=boundary_z, node_color='red')\n",
    "#     plt.title(\"Z-Error Matching Graph (Nodes are X-Stabilizers)\")\n",
    "#     plt.show()\n",
    "# except Exception as e:\n",
    "#     print(f\"Install networkx and matplotlib to visualize graphs. Error: {e}\")\n",
    "\n",
    "\n",
    "# --- Create the Main Quantum Circuit (Similar to before) ---\n",
    "qreg = QuantumRegister(TOTAL_QUBITS, 'q')\n",
    "creg_syndrome = ClassicalRegister(NUM_SYNDROME_BITS, 'syndrome')\n",
    "qc = QuantumCircuit(qreg, creg_syndrome)\n",
    "\n",
    "# 1. Initialize Logical State (|0>) - Default\n",
    "\n",
    "# 2. Introduce a Single Qubit Error\n",
    "print(\"\\n--- Introducing Error ---\")\n",
    "# --- Try different errors ---\n",
    "error_qubit_index = 4 # Data qubit index (e.g., 1, 3, 4, 5, 7, 9, 11, 12, 13)\n",
    "error_type = 'X'   # Try 'X', 'Z', 'Y', or None\n",
    "# ---\n",
    "\n",
    "if error_type and error_qubit_index in DATA_QUBITS:\n",
    "    print(f\"Applying {error_type} error on data qubit {error_qubit_index}\")\n",
    "    if error_type == 'X': qc.x(error_qubit_index)\n",
    "    elif error_type == 'Z': qc.z(error_qubit_index)\n",
    "    elif error_type == 'Y': qc.y(error_qubit_index)\n",
    "    qc.barrier()\n",
    "elif error_qubit_index not in DATA_QUBITS and error_type is not None:\n",
    "     print(f\"Warning: Qubit {error_qubit_index} is an ancilla or invalid. No error applied.\")\n",
    "     error_type = None\n",
    "else:\n",
    "    print(\"No error applied.\")\n",
    "    error_type = None\n",
    "\n",
    "# 3. Measure Stabilizers (Syndrome Measurement)\n",
    "print(\"\\n--- Measuring Stabilizers ---\")\n",
    "for measure_qubit_index in ancilla_order_for_syndrome:\n",
    "    stab_info = stabilizers[measure_qubit_index]\n",
    "    cl_bit_index = syndrome_bit_map[measure_qubit_index]\n",
    "    measure_stabilizer(qc, measure_qubit_index, stab_info, cl_bit_index)\n",
    "    # qc.barrier() # Optional barrier\n",
    "\n",
    "\n",
    "# --- Simulate the Circuit (Same as before) ---\n",
    "print(\"\\n--- Simulating ---\")\n",
    "simulator = AerSimulator()\n",
    "job = simulator.run(qc, shots=1)\n",
    "result = job.result()\n",
    "counts = result.get_counts(qc)\n",
    "print(f\"Simulation Counts: {counts}\")\n",
    "\n",
    "# --- Decode the Syndrome using PyMatching ---\n",
    "print(\"\\n--- Decoding with PyMatching (MWPM) ---\")\n",
    "\n",
    "# Get the measured syndrome string and convert to list/tuple\n",
    "syndrome_str_qiskit = list(counts.keys())[0]\n",
    "syndrome_str = syndrome_str_qiskit[::-1] # Order: Z0..Z3, X0..X3\n",
    "syndrome_full = np.array([int(bit) for bit in syndrome_str])\n",
    "\n",
    "print(f\"Measured Syndrome (Z0..Z3, X0..X3): {syndrome_full.tolist()}\")\n",
    "\n",
    "# --- Prepare inputs for PyMatching (REVISED) ---\n",
    "\n",
    "# Syndrome for X-errors (uses Z-stabilizer outcomes: bits 0-3)\n",
    "# Array size matches number of nodes in graph_x (which is num Z stabilizers)\n",
    "syndrome_x_part = np.zeros(graph_x.number_of_nodes(), dtype=np.uint8)\n",
    "for anc_idx, graph_node_idx in node_map_x.items():\n",
    "    syndrome_bit_idx = syndrome_bit_map[anc_idx] # Get index (0-3) in full syndrome\n",
    "    syndrome_x_part[graph_node_idx] = syndrome_full[syndrome_bit_idx]\n",
    "print(f\"Syndrome for X-Error Graph (Nodes 0..{graph_x.number_of_nodes()-1}=Z-Stabs): {syndrome_x_part.tolist()}\")\n",
    "\n",
    "# Syndrome for Z-errors (uses X-stabilizer outcomes: bits 4-7)\n",
    "# Array size matches number of nodes in graph_z (which is num X stabilizers)\n",
    "syndrome_z_part = np.zeros(graph_z.number_of_nodes(), dtype=np.uint8)\n",
    "for anc_idx, graph_node_idx in node_map_z.items():\n",
    "    syndrome_bit_idx = syndrome_bit_map[anc_idx] # Get index (4-7) in full syndrome\n",
    "    syndrome_z_part[graph_node_idx] = syndrome_full[syndrome_bit_idx]\n",
    "print(f\"Syndrome for Z-Error Graph (Nodes 0..{graph_z.number_of_nodes()-1}=X-Stabs): {syndrome_z_part.tolist()}\")\n",
    "\n",
    "\n",
    "# --- Initialize PyMatching Objects (REVISED) ---\n",
    "# Pass the graph and the list of boundary node indices\n",
    "matcher_x = pymatching.Matching(graph_x, boundary_nodes=boundary_x)\n",
    "matcher_z = pymatching.Matching(graph_z, boundary_nodes=boundary_z)\n",
    "\n",
    "# --- Decode ---\n",
    "# Pass the syndrome array corresponding ONLY to the stabilizer nodes\n",
    "correction_x_indices = matcher_x.decode(syndrome_x_part, return_corrected_Jeg_indices=True)\n",
    "correction_z_indices = matcher_z.decode(syndrome_z_part, return_corrected_Jeg_indices=True)\n",
    "\n",
    "# The returned indices refer to edges in the graph's internal representation.\n",
    "# It's often easier to get the correction in terms of which *nodes* need flipping.\n",
    "# Let's decode again to get the correction array (size = num_nodes = num_stabilizers)\n",
    "# correction_array[i] = 1 means node i needs correction relative to the MWPM solution\n",
    "correction_array_x = matcher_x.decode(syndrome_x_part)\n",
    "correction_array_z = matcher_z.decode(syndrome_z_part)\n",
    "\n",
    "print(f\"MWPM Correction Array (X-Error Graph Nodes): {correction_array_x.tolist()}\")\n",
    "print(f\"MWPM Correction Array (Z-Error Graph Nodes): {correction_array_z.tolist()}\")\n",
    "\n",
    "# --- Interpret the Correction (Needs Careful Thought) ---\n",
    "# This part is tricky. The correction_array tells us which stabilizer nodes\n",
    "# were involved in the MWPM solution. We need to map this back to the most likely\n",
    "# physical error(s) on data qubits.\n",
    "\n",
    "# Strategy:\n",
    "# 1. Find which nodes are indicated by correction_array_x and correction_array_z.\n",
    "# 2. Identify the original syndrome nodes.\n",
    "# 3. The difference between corrected nodes and syndrome nodes might imply internal edges used.\n",
    "# 4. Boundary connections are implicit. If a syndrome node is also a corrected node AND a boundary node,\n",
    "#    it likely implies a boundary edge was used in the matching.\n",
    "# 5. Map edges/boundary connections back to data qubits.\n",
    "\n",
    "# Let's try a simpler interpretation based on the original syndrome:\n",
    "# If syndrome_x_part has a single '1' at index `i`, and `i` is in `boundary_x`, assume an X error on a data qubit flipping only stab `i`.\n",
    "# If syndrome_z_part has a single '1' at index `j`, and `j` is in `boundary_z`, assume a Z error on a data qubit flipping only stab `j`.\n",
    "# If syndrome_x_part has two '1's at `i1`, `i2`, assume an X error on a data qubit flipping stabs `i1`, `i2`.\n",
    "# etc.\n",
    "\n",
    "predicted_x_error_qubits = set()\n",
    "predicted_z_error_qubits = set()\n",
    "\n",
    "syndrome_nodes_x_indices = np.where(syndrome_x_part == 1)[0]\n",
    "syndrome_nodes_z_indices = np.where(syndrome_z_part == 1)[0]\n",
    "\n",
    "# Simple interpretation for SINGLE errors (most likely for d=3)\n",
    "if len(syndrome_nodes_x_indices) == 1:\n",
    "    node_idx = syndrome_nodes_x_indices[0]\n",
    "    if node_idx in boundary_x:\n",
    "        # Find data qubits flipping ONLY this Z-stabilizer\n",
    "        anc_idx = z_ancillas[node_idx] # Get the original ancilla index\n",
    "        for dq in data_qubits:\n",
    "            flipped_ancillas = [anc for anc in z_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "            if len(flipped_ancillas) == 1 and flipped_ancillas[0] == anc_idx:\n",
    "                 predicted_x_error_qubits.add(dq) # Could be multiple dq's if degenerate\n",
    "elif len(syndrome_nodes_x_indices) == 2:\n",
    "    node1, node2 = syndrome_nodes_x_indices\n",
    "    # Find data qubits flipping BOTH these Z-stabilizers\n",
    "    anc1 = z_ancillas[node1]\n",
    "    anc2 = z_ancillas[node2]\n",
    "    for dq in data_qubits:\n",
    "        flipped_ancillas = [anc for anc in z_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "        if len(flipped_ancillas) == 2 and set(flipped_ancillas) == {anc1, anc2}:\n",
    "            predicted_x_error_qubits.add(dq)\n",
    "\n",
    "if len(syndrome_nodes_z_indices) == 1:\n",
    "    node_idx = syndrome_nodes_z_indices[0]\n",
    "    if node_idx in boundary_z:\n",
    "        # Find data qubits flipping ONLY this X-stabilizer\n",
    "        anc_idx = x_ancillas[node_idx] # Get the original ancilla index\n",
    "        for dq in data_qubits:\n",
    "            flipped_ancillas = [anc for anc in x_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "            if len(flipped_ancillas) == 1 and flipped_ancillas[0] == anc_idx:\n",
    "                 predicted_z_error_qubits.add(dq)\n",
    "elif len(syndrome_nodes_z_indices) == 2:\n",
    "    node1, node2 = syndrome_nodes_z_indices\n",
    "    # Find data qubits flipping BOTH these X-stabilizers\n",
    "    anc1 = x_ancillas[node1]\n",
    "    anc2 = x_ancillas[node2]\n",
    "    for dq in data_qubits:\n",
    "        flipped_ancillas = [anc for anc in x_ancillas if dq in stabilizers[anc]['data_qubits']]\n",
    "        if len(flipped_ancillas) == 2 and set(flipped_ancillas) == {anc1, anc2}:\n",
    "            predicted_z_error_qubits.add(dq)\n",
    "\n",
    "# (This interpretation assumes MWPM finds the single error path for single syndromes)\n",
    "\n",
    "# Combine Predictions\n",
    "corrections = []\n",
    "common_qubits = predicted_x_error_qubits.intersection(predicted_z_error_qubits)\n",
    "only_x_qubits = predicted_x_error_qubits - common_qubits\n",
    "only_z_qubits = predicted_z_error_qubits - common_qubits\n",
    "\n",
    "for q in common_qubits: corrections.append(f\"Y on Q{q}\")\n",
    "for q in only_x_qubits: corrections.append(f\"X on Q{q}\")\n",
    "for q in only_z_qubits: corrections.append(f\"Z on Q{q}\")\n",
    "\n",
    "# Handle potential degeneracies (multiple qubits predicted for one syndrome part)\n",
    "# For d=3 single error, expect only one qubit total. If more, pick one arbitrarily or flag.\n",
    "if len(corrections) > 1:\n",
    "     predicted_error = f\"Ambiguous ({', '.join(corrections)})\"\n",
    "     predicted_type = \"Ambiguous\"\n",
    "     predicted_qubit = \"N/A\"\n",
    "elif len(corrections) == 1:\n",
    "     predicted_error = corrections[0]\n",
    "     parts = predicted_error.split()\n",
    "     predicted_type = parts[0]\n",
    "     predicted_qubit = int(parts[-1][1:])\n",
    "else:\n",
    "     predicted_error = \"None\"\n",
    "     predicted_type = None\n",
    "     predicted_qubit = None\n",
    "\n",
    "\n",
    "print(f\"\\nDecoder Prediction (Simplified Interpretation): {predicted_error}\")\n",
    "\n",
    "# --- Explanation (Same as before, checks against prediction) ---\n",
    "print(\"\\n--- Explanation ---\")\n",
    "is_error_detected = np.any(syndrome_full)\n",
    "\n",
    "if not is_error_detected:\n",
    "    if error_type is None:\n",
    "        print(\"Correct: No error introduced, syndrome is zero.\")\n",
    "    else:\n",
    "        print(f\"Result: Error ({error_type} on Q{error_qubit_index}) introduced, but syndrome is zero (Undetected - Logical Error or Boundary Issue).\")\n",
    "else: # Error detected\n",
    "    if error_type is None:\n",
    "        print(f\"Result: No error introduced, but non-zero syndrome {syndrome_full.tolist()} detected (Problem!).\")\n",
    "    else: # Error introduced and detected\n",
    "        print(f\"Correct: Error ({error_type} on Q{error_qubit_index}) introduced, non-zero syndrome {syndrome_full.tolist()} detected.\")\n",
    "        if predicted_error == \"None\":\n",
    "            print(\"Decoder failed to find a likely single error cause based on simple interpretation.\")\n",
    "        elif predicted_type == \"Ambiguous\":\n",
    "            print(f\"Decoder Prediction is Ambiguous: {predicted_error}. Input was {error_type} on Q{error_qubit_index}.\")\n",
    "            print(\"(This suggests the stabilizer definitions might lead to degenerate syndromes for single errors).\")\n",
    "        else:\n",
    "            print(f\"Decoder suggests correction: {predicted_error}\")\n",
    "            # Check if prediction matches input (for single qubit errors)\n",
    "            if predicted_type == error_type and predicted_qubit == error_qubit_index:\n",
    "                print(f\"Success: Decoder correctly identified the single {error_type} error on qubit {error_qubit_index}.\")\n",
    "            else:\n",
    "                 print(f\"Mismatch: Decoder predicted {predicted_type} on {predicted_qubit}, but input was {error_type} on {error_qubit_index}.\")\n",
    "                 print(\"(This might indicate graph definition issues, interpretation limitations, or MWPM finding an equivalent error).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
